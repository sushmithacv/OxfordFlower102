{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# **Loading the Oxford Flowers 102 Dataset**\n",
        "dataset, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "train_data, test_data = dataset['train'], dataset['test']\n",
        "\n",
        "# Check dataset info\n",
        "print(info)\n",
        "print(f'Train data size: {len(train_data)}, Test data size: {len(test_data)}')\n",
        "\n",
        "# **Data Preprocessing**\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (150, 150))  # Resize to 150x150\n",
        "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(format_image).batch(32).shuffle(1000)\n",
        "test_data = test_data.map(format_image).batch(32)\n",
        "\n",
        "# **Displaying Sample Image**\n",
        "for image_batch, label_batch in train_data.take(1):\n",
        "    plt.imshow(image_batch[0])  # Display the first image\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print('Label:', label_batch[0].numpy())  # Display the label of the first image\n",
        "\n",
        "# **Building the Convolutional Neural Network**\n",
        "model = models.Sequential([\n",
        "    # First convolutional block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Second convolutional block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Third convolutional block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Fourth convolutional block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Fifth convolutional block\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Sixth convolutional block\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Seventh convolutional block\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Eighth convolutional block\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Flattening the output and adding dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Adding dropout to reduce overfitting\n",
        "    layers.Dense(102, activation='softmax')  # 102 classes for Oxford Flowers\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# **Training the Model**\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(train_data, epochs=20, validation_data=test_data, callbacks=[early_stopping])\n",
        "\n",
        "# **Evaluating the Model**\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "# **Plotting Accuracy and Loss**\n",
        "def plot_metrics(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_metrics(history)\n",
        "\n",
        "# **Saving the Model**\n",
        "# Use a relative path that is not nested too deep for Streamlit deployment\n",
        "model_save_path = 'https://github.com/sushmithacv/OxfordFlower102/trained_oxford_flowers_model.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved at {model_save_path}\")\n",
        "\n",
        "# **Loading the Model in Streamlit**\n",
        "# In your Streamlit app, use error handling to load the model\n",
        "def load_model_with_error_handling():\n",
        "    if os.path.exists(model_save_path):\n",
        "        model = models.load_model(model_save_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Error: Model file {model_save_path} not found.\")\n",
        "        return None\n",
        "    return model\n",
        "\n",
        "# Example usage in Streamlit\n",
        "# model = load_model_with_error_handling()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
